<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Applied C++20 Coroutines</title>

    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico?">

    <link rel="stylesheet" href="dist/reset.css">
    <link rel="stylesheet" href="dist/reveal.css">
    <link rel="stylesheet" href="dist/theme/league.css" id="theme">

    <!-- Theme used for syntax highlighted code -->
    <link rel="stylesheet" href="plugin/highlight/github.css" id="highlight-theme">

  </head>
  <body>
    <div class="reveal">
      <div class="slides">

        <section id="Title-Slide"
                 data-state="hideControls"
                 data-menu-title="Title Slide"
                 data-background-image="media/title-slide.png"
                 data-background-size="contain">
        </section>

        <section data-menu-title="Applied C++20 Coroutines">
          <h2>Applied C++20 Coroutines</h2>
          <p>
            <small>
              Jim (James) Pascoe<br>
              <a href="http://www.james-pascoe.com">http://www.james-pascoe.com</a><br>
              <a href="mailto:james@james-pascoe.com">james@james-pascoe.com</a><p>

              <a href="http://jamespascoe.github.io/accu2023">http://jamespascoe.github.io/accu2023</a><br>
              <a href="https://github.com/jamespascoe/accu2023-example-code.git">https://github.com/jamespascoe/accu2023-example-code.git</a>
              <p>
              <font style="color:yellow">ACCU Bristol and Bath Meetup Coordinator</font>
            </small>
        </section>

        <section data-menu-title="What Next?">
          <span class="fragment"><h3 style="color:yellow">Coroutines ...</span><span class="fragment"> What Next?</h3></span>
          <p>
            <ol>
              <span class="fragment"><li>Fit within the wider concurrency framework</li></span>
              <span class="fragment"><li>More examples (real-world and learning)</li></span>
              <span class="fragment"><li>Empirical measurements</li></span>
              <span class="fragment"><li>Library support and the future</li></span>
            </ol>
            <aside class="notes">
            Coroutines still feel a bit ephemeral. Deeply technical, still quite difficult to know when
            to use them. I want to address this in this talk.
            </aside>
        </section>

        <section>
          <h2>Outline</h2>
          <ul>
            <span class="fragment"><li>Concurrency in Modern C++</li></span>
            <ul>
              <span class="fragment"><li>How C++20 Coroutines fit</span><span class="fragment"> (and work)</li></span>
            </ul>
            <span class="fragment"><li><a href="https://www.bluwireless.com/products/5g-tactical/">Mobile Wireless Networking</a> with Coroutines</li></span>
            <span class="fragment"><li>C++20 Example: Web Serving with <a href="https://www.boost.org/doc/libs/1_81_0/libs/beast/doc/html/index.html">Boost.Beast</a></li></span>
            <ul>
              <span class="fragment"><li>Asynchronous, <a href="https://www.boost.org/doc/libs/1_81_0/libs/coroutine2/doc/html/coroutine2/overview.html">Boost.Coroutine</a>, 
                  <a href="https://www.boost.org/doc/libs/1_81_0/libs/beast/example/http/server/awaitable/http_server_awaitable.cpp">Awaitables</a></li></span>
              <span class="fragment"><li>Empirical analysis with <a href="https://httpd.apache.org/docs/2.4/programs/ab.html">Apache bench</a> (ab)</li></span>
            </ul>
            <span class="fragment"><li><a href="http://wg21.link/p2502">std::generator</a>, <a href="http://wg21.link/p2300">std::execution</a> and <a href="https://github.com/facebookexperimental/libunifex">libunifex</a></li></span>
          </ul>
          <aside class="notes">
          </aside>
        </section>

        <section>
          <h2><a href="https://github.com/jamespascoe/accu2023-example-code.git">Example Code: Tools & Build</a></h2>
            <ul>
              <span class="fragment"><li>C++ examples all compile with <a href="https://gcc.gnu.org/gcc-12/changes.html">GCC 12.2</a>:</li></span>
              <span class="fragment"><ul><li><a href="https://www.boost.org/doc/libs/1_81_0/libs/beast/doc/html/index.html">Boost 1.81.0</a></li></span>
              <span class="fragment"><li><a href="https://www.swig.org/">SWIG 4.0.2</a></li></span>
              <span class="fragment"><li><a href="https://www.cmake.org/">CMake 3.25.2</a></li></ul></span>
              <span class="fragment"><li>Lua examples run with <a href="https://www.lua.org/download.html">Lua 5.4.4</a></li></span>
              <span class="fragment"><li>Tested on Linux Mint 19 and Mac OS X (<font size="6">Mojave</font>, <font size="6">Big Sur</font>)</li></span>
            </ul>
          <aside class="notes">
          </aside>
        </section>

      <section>
        <section data-menu-title="Concurrency Back-to-Basics" data-background-video="media/BWT_Intermission.mp4" data-background-video-loop=true>
          <h1>Concurrency<br>Back-to-Basics</h1>
        </section>

        <section>
          <h2><a href=https://www.gnu.org/software/pth/pth-manual.html#threading_background">Concurrency vs. Parallelism</a></h2>
            <ul>
              <span class="fragment" style="color:yellow"><li>Concurrency exists when:</li></span>
              <ul>
                <span class="fragment"><li>multiple items of work are 'in progress'</li></span>
                <span class="fragment"><li>e.g. processes, threads or coroutines</li></span>
                <span class="fragment"><li>harnessing windows of latency</li></span>
              </ul><br>
              <span class="fragment" style="color:yellow"><li>Parallelism exists when:</li></span>
              <ul>
                <span class="fragment"><li>multiple items of work execute simultaneously</li></span>
                <span class="fragment"><li>e.g. threads running on separate CPU cores</li></span>
                <span class="fragment"><li>execution occurs at the same instant in time</li></span>
              </ul>
            </ul>
            <aside class="notes">
            Concurrency exists when at least two threads are 'in progress' at the same time.
            Parallelism arises when at least two threads are executing simultaneously.

            I think it was Arthur O'Dwyer at CppCon 2020 who said that broadly speaking, parallelism in the context of Computer Science
            generally requires some form of hardware. So, for example, my MAC is a quad core Intel i7 that's based on the Haswell
            architecture. So this means it can run four threads, in parallel, at the same instant. If we go one level deeper we can
            see that the Haswell microarchitecture is a dual-threaded, out-of-order microprocessor that is capable of decoding 5
            instructions, issuing 4 fused uops (micro operations) and dispatching 8 uops on each cycle (and its clocked at 4GHz).
            </aside>
        </section>

        <section data-menu-title="Concurrency">
          <img class="stretch" data-src="media/concurrency.png" style="background:none; border:none; box-shadow:none;">
        </section>

        <section data-menu-title="Parallelism">
          <img class="stretch" data-src="media/parallelism.png" style="background:none; border:none; box-shadow:none;">
        </section>

        <section>
          <h2><a href="https://www.boost.org/doc/libs/1_81_0/libs/fiber/doc/html/fiber/overview.html">Concurrency Hierarchy</a></h2>
            <ol>
              <span class="fragment"><li>Multiple processes run on a single computer</li></span>
              <span class="fragment"><li>Multiple threads run within a single process</li></span>
              <span class="fragment"><li>Multiple coroutines run within a single thread</li></span>
            </ol>
            <p>
            <span class="fragment" style="color:yellow">Concurrency allows us to harness latency</span>
            <aside class="notes">
            A note of clarification with the terms 'Coroutine' and 'Fibers'. They are sometimes used inter-changeably and
            there are differences. Fibers give you a co-operatively scheduled light-weight threading model, which resembles OS threads.
            You can implement fibers with coroutines (which is exactly what Lua and Boost.Fiber do), but coroutines themselves give you
            more, for example, the capability to implement generators.
            </aside>
        </section>

        <section>
          <h2><a href="https://www.gnu.org/software/pth/pth-manual.html#threading_background">Processes</a></h2>
            <ul>
              <span class="fragment"><li>OS 'multitasks' by forking processes</li></span>
              <span class="fragment"><li>Context switch occurs when:</li></span>
              <ul>
                <span class="fragment"><li>a process is blocked (e.g. semaphore)</li></span>
                <span class="fragment"><li>or a pre-emptive time slice expires</li></span>
              </ul>
              <span class="fragment"><li>Overhead is high:</li></span>
              <ul>
                <span class="fragment"><li>VM tables, program code, heap, stack, fds, signals</li></span>
                <span class="fragment"><li>Sharing data, synchronisation and scaling are hard</li></span>
              </ul>
            </ul>
            <aside class="notes">
            Event-driven applications are characterised by two things, background processing tasks and lots of one-off requests that have
            to be serviced. If you think about networking and GUIs, this is especially true.

            Key point: if a process blocks after 5% of its time-slice, then the whole thing is context-switched, despite the possibility
            that useful work can be done in other parts of the process.
            </aside>
        </section>

        <section>
          <h2><a href="https://www.gnu.org/software/pth/pth-manual.html#threading_background">Threads</a></h2>
            <ul>
              <span class="fragment"><li>Light-weight threads in a heavy-weight process</li></span>
              <span class="fragment"><li>Lower overhead (faster context switch):</li></span>
              <ul>
                <span class="fragment"><li>... stack, program counter, signal table</li></span>
              </ul>
              <span class="fragment"><li>C++03: OS, C++11: std::thread, C++20: std::jthread</li></span>
              <span class="fragment" style="color:yellow"><li><a href="">Reentrancy</a>: correct when executed simultaneously</li></span>
              <span class="fragment" style="color:yellow"><li><a href="">Thread safety</a>: the avoidance of race conditions</li></span>
              <span class="fragment" style="color:yellow"><li><a href="https://en.wikipedia.org/wiki/Green_thread">Green Threads</a>: scheduled by a runtime library / VM</li></span>
            </ul>
            <aside class="notes">
            Green Threads are threads that are scheduled by a runtime library or a virtual machine (so not an OS thread). The name actually
            comes from the early days of Java - it was a co-operative threading model in Java 1.1, that was abandoned in 1.3 (back in the days
            of the JDK 1.x for anyone that remembers it).
            </aside>
        </section>

        <section>
          <h2><a href="https://en.cppreference.com/w/cpp/language/coroutines">Coroutines</a> (as <a href="http://wg21.link/n4024">Fibers</a>)</h2>
            <ul>
              <span class="fragment"><li>Multiple coroutines in a single thread</li></span>
              <span class="fragment"><li>Scheduled by a 'dispatcher' (same thread)</li></span>
              <span class="fragment"><li>No races, synchronisation or data sharing issues</li></span>
              <span class="fragment"><li>Allows work when part of the thread is blocked</li></span>
              <span class="fragment" style="color:yellow"><li>See <a href="https://www.boost.org/doc/libs/1_81_0/libs/fiber/doc/html/fiber/overview.html">Boost.Fiber</a> for details</li></span>
            </ul>
            <aside class="notes">
            </aside>
        </section>

      </section>
      <section>

        <section data-background-video="media/BWT_Intermission.mp4" data-background-video-loop=true>
          <h1>Coroutines in the Field</h1>
        </section>

        <section>
          <h2><a href="http://bluwireless.com/applications/defence-and-perimeter-security/">Blu Wireless:</a> <a href="https://www.bluwireless.com/applications/defence-and-perimeter-security/">Mobile Mesh</a></h2>
          <ul>
            <span class="fragment"><li>IP networking over 5G mmWave (60 GHz) modems</li></span>
            <span class="fragment"><ul><li>802.11ad MAC + PHY (Hydra) + software</li></ul></span>
            <span class="fragment"><li>High-bandwidth, low latency mobile Internet</li></span>
            <span class="fragment"><ul><li>Up to 3 Gbps wireless links (up to 4 km)</ul></span>
            <span class="fragment"><li>Embedded quad-core ARMv8 NPUs</li></span>
          </ul>
          <aside class="notes">
          </aside>
        </section>

        <section data-menu-title="Mobile Mesh Video"
                 data-state="hideControls",
                 data-background-video="media/BWT_MobileMesh.mp4"
                 id="video">
        </section>

        <section data-menu-title="Blu Wireless Devices">
          <img class="stretch" data-src="media/5G-tactical-comms.png" style="background:none; border:none; box-shadow:none;">
        </section>

        <section data-menu-title="Connection Management">
          <h2><a href="https://www.bluwireless.com/products/mobile-connection-manager/">Mobile Connection Management</a></h2>
          <ul>
            <span class="fragment"><li>L1 management implemented using coroutines</li></span>
            <ul>
              <span class="fragment"><li>Combination of Modern C++ (17/20) and Lua</li></span>
            </ul>
            <span class="fragment"><li>Lots of asynchronous operations</li></span>
            <ul>
              <span class="fragment"><li>Scan, Connect, Disconnect</li></span>
              <span class="fragment"><li>Around 40 primitives (called 'Actions')</li></span>
            </ul>
            <span class="fragment"><li>Groups of coroutines operate in threads</li></span>
            <ul>
              <span class="fragment"><li>No race conditions or data sharing limitations</li></span>
              <span class="fragment"><li>Concurrency combined with Parallelism</li></span>
            </ul>
          </ul>
          <aside class="notes">
          </aside>
        </section>

        <section data-menu-title="Mobile Mesh Architecture">
          <img class="stretch" data-src="media/mobile_mesh_architecture.png" style="background:none; border:none; box-shadow:none;">
        </section>

        <section data-menu-title="Lua Fiber Example">
          <h2><a href="">Example: Lua Networking Fibers</a></h2>
          <ul>
            <span class="fragment"><li>Lua behaviour: two nodes sending messages</li></span>
            <span class="fragment"><li>Includes two actions: 'Connector' and 'Log'</li></span>
            <span class="fragment"><li>Also provides: <a href="http://swig.org">SWIG</a>, CMake, Lua 'main' code</li></span>
            <span class="fragment"><li>Other bindings exist: e.g. 
              <a href="https://github.com/ThePhD/sol2">the PhD's Sol3</a></li>
            </span>
          </ul>
          <aside class="notes">
          This example is designed to be fairly powerful. Simple Lua behaviour (that's easy to grasp), but the
          architecture on which it sits is powerful. C++ to Lua bindings via Swig, multi-level logging using
          spdlog, network comms via Boost.Asio with a CMake build flow. So, the idea is that the example is
          straightforward to grasp but then you can clone it, take it forward and use it in your own work.
          </aside>
        </section>

        <section data-menu-title="Lua Fibers Architecture">
          <img class="stretch" data-src="media/lua_fibers.png" style="background:none; border:none; box-shadow:none;">
        </section>

        <section>
          <h2><a href="https://github.com/jamespascoe/accu2023-example-code/blob/master/lua_fiber/behaviours/lua_fiber.lua">Lua Behavior</a></h2>
          <pre class="stretch"><code class="lua" data-trim data-line-numbers="|102-130|15-43|45-73|68-100|">
--[[

 lua_fiber.lua - provides a simple example of fibers.

]]

function ping_fiber (connector, remote_port)

  Actions.Log.info(
    "ping_fiber: connecting to port: " .. remote_port
  )

  local timer = Actions.Timer()

  -- Connect to a node and send a 'ping' message
  while true do

    connector:Send("localhost", remote_port, "PING")

    repeat
      coroutine.yield()
    until (connector:IsMessageAvailable())

    Actions.Log.info(
      "ping_fiber: received: " .. connector:GetNextMessage()
    )

    timer(Actions.Timer.WaitType_NOBLOCK, 1, "s", 1)
    while timer:IsWaiting() do
      coroutine.yield()
    end

  end

end

function pong_fiber (connector, remote_port)

  Actions.Log.info(
    "pong_fiber: connecting to port: " .. remote_port
  )

  local timer = Actions.Timer()

  -- Connect to a node and send a 'pong' message
  while true do

    repeat
      coroutine.yield()
    until (connector:IsMessageAvailable())

    Actions.Log.info(
      "pong_fiber: received: " .. connector:GetNextMessage()
    )

    connector:Send("localhost", remote_port, "PONG")

    timer(Actions.Timer.WaitType_NOBLOCK, 1, "s", 2)
    while timer:IsWaiting() do
      coroutine.yield()
    end

  end

end

-- Coroutine dispatcher (see Section 9.4 of 'Programming in Lua')
function dispatcher (coroutines)

  local timer = Actions.Timer()

  while true do
    if next(coroutines) == nil then break end -- all done

    for name, co in pairs(coroutines) do
      local status, res = coroutine.resume(co)

      if res then -- coroutine has exited

        if type(res) == "string" then  -- runtime error
          Actions.Log.critical("Lua coroutine '" .. tostring(name)
                               .. "' exited with error " .. res)
        else
          Actions.Log.warn("Lua coroutine '" .. tostring(name) ..
                           "' has exited")
        end

        coroutines[name] = nil

        break
      end
    end

    -- Run the dispatcher every 1 ms. Note, that a blocking
    -- timer is required to prevent lua_mesh from consuming
    -- 100% of a core.
    timer(Actions.Timer.WaitType_BLOCK, 1, "ms", 3)

  end
end

local function main(args)

  print("Welcome to Lua Mesh !")

  if (not args or not args["port"]) then
    print("Usage: lua_mesh lua_mesh.lua -a port=&ltlisten port&gt")
    os.exit(1)
  end

  print(
    string.format("Starting LuaMesh:\n" ..
                  "  listen port: %d\n", tonumber(args["port"]))
  )

  local connector = Actions.Connector(args["port"])
  local remote_port = args["port"] == 7777 and "8888" or "7777"

  -- Create co-routines
  local coroutines = {}
  coroutines["ping"] = coroutine.create(ping_fiber)
  coroutine.resume(coroutines["ping"], connector, remote_port)

  coroutines["pong"] = coroutine.create(pong_fiber)
  coroutine.resume(coroutines["pong"], connector, remote_port)

  -- Run the main loop
  dispatcher(coroutines)

end

local behaviour = {
  name = "lua_fiber",
  description = "A Lua behaviour to demonstrate fibers",
  entry_point = main
}

return behaviour
          </code></pre>
        </section>

        <section data-menu-title="Connector Action: hpp">
          <h2><a href="https://github.com/jamespascoe/accu2023-example-code/blob/master/lua_fiber/src/actions/lua_fiber_action_connector.hpp">Connector Action</a></h2>
            <pre class="stretch"><code class="c++" style="width:102%" data-trim data-line-numbers="|43-61|">
//
// lua_fiber_connector_action.hpp
//

#include "asio/asio.hpp"

class Connector {
public:
  enum class ErrorType { SUCCESS, RESOLVE_FAILED, CONNECT_FAILED };

  inline static int const default_port = 7777;

  Connector(unsigned short port = default_port);

  ~Connector();

  // Do not allow instances to be copied or moved
  Connector(Connector const& rhs) = delete;
  Connector(Connector&& rhs) = delete;
  Connector& operator=(Connector const& rhs) = delete;
  Connector& operator=(Connector&& rhs) = delete;

  // Send a message to a remote behaviour
  ErrorType Send(std::string const& hostname_or_ip,
                 std::string const& port,
                 std::string const& message);

  // Returns whether a message is available to be read
  bool IsMessageAvailable(void) { return !m_messages.empty(); }

  // Returns the most recent message (or an empty string if none
  // are available)
  std::string GetNextMessage(void);

private:
  using tcp = asio::ip::tcp;

  // Max number of messages to retain
  inline static const int max_messages = 32;

  // Encapsulate a TCP connection and the data sent over it. Note
  // that this is based on the ASIO Asychronous TCP server tutorial.
  class tcp_connection {
  public:
    using pointer = std::shared_ptr&lttcp_connection&gt;

    static pointer create(asio::io_context& io_context) {
      return pointer(new tcp_connection(io_context));
    }

    tcp::socket& socket() { return m_socket; }

    std::string& data() { return m_data; }

  private:
    tcp_connection(asio::io_context& io_context) :
      m_socket(io_context) {}

    tcp::socket m_socket;
    std::string m_data;
  };

  // Asynchronous handlers for reading and accepting connections
  void handle_read(asio::error_code const& error,
                   std::size_t bytes_transferred,
                   tcp_connection::pointer connection);

  void handle_write(asio::error_code const& error,
                    std::size_t bytes_transferred,
                    tcp_connection::pointer connection);

  void handle_accept(tcp_connection::pointer new_connection,
                     asio::error_code const& error);

  void start_accept();

  // Member variables
  asio::io_context m_io_context;
  asio::ip::tcp::acceptor m_acceptor;

  std::thread m_thread;

  // FIFO vector to store received messages
  std::vector&ltstd::string&gt m_messages;
};
          </code></pre>
          <aside class="notes">
          </aside>
        </section>

        <section data-menu-title="Connector Action: cpp">
          <h2><a href="https://github.com/jamespascoe/accu2023-example-code/blob/master/lua_fiber/src/actions/lua_fiber_action_connector.cpp">Connector Action</a></h2>
            <pre class="stretch"><code class="c++" style="width:102%" data-trim data-line-numbers="">
//
// lua_fiber_connector_action.cpp
//

#include "lua_fiber_action_connector.hpp"

#include "lua_fiber_log_manager.hpp"

Connector::Connector(unsigned short port)
    : m_acceptor(m_io_context, tcp::endpoint(tcp::v4(), port)) {
  start_accept();

  m_thread = std::thread([this]() { m_io_context.run(); });

  log_trace("Connector action starting");
}

Connector::~Connector() {
  log_trace("Cleaning up in Connector action");

  m_io_context.stop();
  m_thread.join();

  log_trace("Connector action exiting");
}

// Send a message to a remote behaviour
Connector::ErrorType Connector::Send(std::string const& host,
                                     std::string const& port,
                                     std::string const& message) {
  // Resolve the destination endpoint
  tcp::resolver resolver(m_io_context);
  tcp::resolver::results_type endpoints;

  try {
    endpoints = resolver.resolve(host, port);
  } catch (asio::system_error& e) {
    log_error(
        "Connector send failed: unable to resolve {}:{}",
        host, port);

    return ErrorType::RESOLVE_FAILED;
  }

  // Open a connection
  tcp_connection::pointer connection =
    tcp_connection::create(m_io_context);

  try {
    asio::connect(connection-&gtsocket(), endpoints);
  } catch (asio::system_error& e) {
    log_error("Connector send failed: could not connect to {}:{}",
              host, port);

    return ErrorType::CONNECT_FAILED;
  }

  asio::async_write(
    connection-&gtsocket(),
    asio::buffer(message),
    [this, connection](const asio::error_code& error,
                       std::size_t bytes_transferred) {
      handle_write(error, bytes_transferred, connection);
    }
  );

  return ErrorType::SUCCESS;
}

// Returns the most recent message (or an empty string
// if none are available)
std::string Connector::GetNextMessage(void) {
  if (!IsMessageAvailable())
    return "";

  std::string ret = m_messages.front();

  m_messages.erase(m_messages.begin());

  return ret;
}

// Asynchronous handlers for reading and accepting connections
void Connector::handle_read(asio::error_code const&gt error,
                            std::size_t bytes_transferred,
                            tcp_connection::pointer connection) {
  if (!error || error == asio::error::eof) {
    // Prevent the message array from growing uncontrollably
    if (m_messages.size() &gt max_messages)
      m_messages.erase(m_messages.begin());

    m_messages.emplace_back(connection-&gt data());

    log_info("Received message ({} bytes): {}",
             bytes_transferred,
             connection-&gtdata());
  } else
    log_error("Connector read error: {}", error.message());
}

// Note the 'maybe_unused' attribute for the TCP connection. This
// ensures that the underlying TCP socket is not closed until the
// write handler has exited.
void Connector::handle_write(
    asio::error_code const& error,
    std::size_t bytes_transferred,
    [[maybe_unused]] tcp_connection::pointer connection) {
  if (!error)
    log_info("Sent message ({} bytes)", bytes_transferred);
  else
    log_error("Connector send error: {}", error.message());
}

void Connector::handle_accept(tcp_connection::pointer connection,
                              asio::error_code const& error) {
  if (!error) {
    log_debug("Accepted message connection");

    asio::async_read(
      connection-&gtsocket(),
      asio::dynamic_buffer(connection-&gtdata()),
      [this, connection](const asio::error_code& error,
                         std::size_t bytes_transferred) {
        handle_read(error, bytes_transferred, connection);
      }
    );
  } else
    log_error("Connector accept error: {}", error.message());

  start_accept();
}

void Connector::start_accept() {
  tcp_connection::pointer connection =
      tcp_connection::create(m_acceptor.get_executor().context());

  m_acceptor.async_accept(
    connection-&gtsocket(),
    [this, connection](const asio::error_code& error) {
      handle_accept(connection, error);
    }
  );
}
          </code></pre>
          <aside class="notes">
          </aside>
        </section>

        <section data-menu-title="Lua Fiber Video"
                 data-state="hideControls",
                 data-background-video="media/lua-fiber-terminal-capture-1080.mp4"
                 id="video">
        </section>

      </section>
      <section>

        <section data-background-video="media/BWT_Intermission.mp4" data-background-video-loop=true>
          <h1>C++20 Coroutines</h1>
        </section>

        <section>
          <h2>Coroutines</h2>
          <span class="fragment" style="color:yellow">Coroutines are subroutines </span>
          <span class="fragment" style="color:yellow">with enhanced semantics</span><p>
          <ul>
            <span class="fragment"><li>Invoked by a caller </span>
            <span class="fragment">(and return to a caller) ...</li></span>
            <span class="fragment"><li>Can suspend execution</li></span>
            <span class="fragment"><li>Can resume execution (at a later time)</li></span>
          </ul>
          <aside class="notes">
          When I am thinking about coroutines, I quite like the term subroutine because a subroutine can be either a function or a coroutine.
          So, the key benefit of a coroutine is its suspension / resumption semantics. A function is called from a caller and then returns.
          A coroutine is initially called from a caller, but can suspend its execution (at which point control is returned to the caller) and
          then 'later' is resumed (typically after an asynchronous event or the completion of some computation).
          </aside>
        </section>

        <section>
          <h2>Benefits</h2>
          <span class="fragment" style="color:yellow">Write asynchronous code ...</span><br>
          <span class="fragment" style="color:yellow">with the readability of synchronous code</span><p>
          <ul>
            <span class="fragment"><li>Useful for networking</li></span>
            <span class="fragment"><li>Lots of blocking operations (connect, send, receive)</li></span>
            <span class="fragment"><li>Multi-threading (send and receive threads)</li></span>
            <span class="fragment"><li>Asynchronous operations mean callbacks</li></span>
            <span class="fragment"><li>Control flow fragments</li></span>
          </ul>
        </section>

        <section data-menu-title="Coroutines in C++20">
          <h2><a href="https://en.cppreference.com/w/cpp/language/coroutines">Coroutine Support in C++20</a></h2>
            <ul>
              <span class="fragment"><li>Three new keywords: <a href="https://en.cppreference.com/w/cpp/language/coroutines#co_await">co_await</a>, <a href="https://en.cppreference.com/w/cpp/language/coroutines#co_yield">co_yield</a>, <a href="https://en.cppreference.com/w/cpp/language/coroutines#co_return">co_return</a></li></span>
              <span class="fragment"><li>New types:</li></span>
              <ul>
                <span class="fragment"><li><a href="https://en.cppreference.com/w/cpp/coroutine/coroutine_handle"><code>coroutine_handle&ltP&gt</code></a></li></span>
                <span class="fragment"><li><a href="https://en.cppreference.com/w/cpp/coroutine/coroutine_traits"><code>coroutine_traits&ltTs...&gt</code></a></li></span>
              </ul>
              <span class="fragment"><li>Trivial awaitables:</li></span>
              <ul>
                <span class="fragment"><li><a href="https://en.cppreference.com/w/cpp/coroutine/suspend_always"><code>std::suspend_always</code></a></li></span>
                <span class="fragment"><li><a href="https://en.cppreference.com/w/cpp/coroutine/suspend_never"><code>std::suspend_never</code></a></li></span>
              </ul>
            </ul>
          <aside class="notes">
          What do we actually get in C++20? Three new keywords and for me, really the star-of-the-show is co_await because
          co_await suspends execution of a coroutine and returns control to the caller. co_yield, yields a value from a coroutine and
          then suspends. So if you think of a generator, co_yield produces a value and then suspends for the next iteration. co_return
          goes one step further by completing execution of the coroutine (and returns a value).
          <p>
          coroutine_handles are pointers to coroutine state and are used to resume and destroy coroutines. coroutine state is a fairly deep concept.
          Usually allocated on the heap (although I think there are some compilers will elide it to the caller's stack) and contains the coroutine's
          promise, parameters, as well as its volatile state, so values of local variables, resumption point etc. Basically anything that is needed
          to resume that coroutine at a later point. And that resumption may take place on some other thread.
          <p>
          coroutine_traits gives you the promise type from a coroutine's return type and its parameters. And then we have two trivial awaitables
          called suspend_always and suspend_never and these are useful in a number of places, typically for controlling whether we want a coroutine
          to begin lazily or eagerly.
          </aside>
        </section>

        <section id="key-references">
          <h2>Key Talks and References</h2>
            <ul>
              <span class="fragment"><li>Lots of good talks at CppCon 2022</li></span>
              <ul>
                <small>
                  <span class="fragment"><li><a href="https://www.youtube.com/watch?v=lm10Cj-HNKQ">Understanding C++ Coroutines by Example: Generators - Pavel Novikov</a></li></span>
                  <span class="fragment"><li><a href="https://www.youtube.com/watch?v=lm10Cj-HNKQ">Deciphering C++ Coroutines - A Diagrammatic Cheat Sheet - Andreas Weis</a></li></span>
                  <span class="fragment"><li><a href="https://www.youtube.com/watch?v=EGqz7vmoKco">C++ Coroutines, from Scratch - Phil Nash</a></li></span>
                  <span class="fragment"><li><a href="https://www.youtube.com/watch?v=8sEe-4tig_A">C++20's Coroutines for Beginners - Andreas Fertig</a></li></span>
                </small>
              </ul>
              <br>
              <span class="fragment"><li><a href="https://lewissbaker.github.io/">Lewis Baker's</a> blog posts:</li></span>
              <ul>
                <small>
                  <span class="fragment"><li><a href="https://lewissbaker.github.io/2017/09/25/coroutine-theory">Coroutine Theory</a></li></span>
                  <span class="fragment"><li><a href="https://lewissbaker.github.io/2017/11/17/understanding-operator-co-await">Understanding operator co_await</a></li></span>
                  <span class="fragment"><li><a href="https://lewissbaker.github.io/2018/09/05/understanding-the-promise-type">Understanding the promise type</a></li></span>
                  <span class="fragment"><li><a href="https://lewissbaker.github.io/2020/05/11/understanding_symmetric_transfer">Understanding Symmetric Transfer</a></li></span>
                </small>
              </ul>
            </ul>
        </section>

        <section>
          <h2><a href="https://lewissbaker.github.io/2017/11/17/understanding-operator-co-await">Awaitable Type</a></h2>
          <ul>
            <span class="fragment"><li>Supports the <code>co_await</code> operator</li></span>
            <span class="fragment"><li>Controls the semantics of an <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/n4775.pdf">await-expression</a></li></span>
            <span class="fragment"><li>Informs the compiler how to obtain the <a href="https://lewissbaker.github.io/2017/11/17/understanding-operator-co-await">awaiter</a></li></span>
          </ul>

          <span class="fragment"><pre><code class="c++" data-trim data-line-numbers="">
co_await async_write(..., use_awaitable);
          </span></code></pre>

          <aside class="notes">
          [after bullets 1-4]

          Ok, so why the distinction? I.e. why do we have the concept of an Awaitable type and an Awaiter?
          So, an awaitable type is a type that supports co_await. But, whether or not co_await can be applied
          directly to a type depends on the context in which the co_await expression appears. The promise type
          can alter the semantics of the co_await expression through an 'await_transform' method and I've got a slide
          coming up on that shortly.

          By contrast the awaiter type allows the user to specify the coroutine's behaviour at specific points in
          the suspension and resumption process. Lets take a look at the awaiter.
          </aside>
        </section>

        <section>
          <h2><a href="https://lewissbaker.github.io/2017/11/17/understanding-operator-co-await">Awaiter Type</a></h2>
          <ul>
            <span class="fragment"><li>Defines suspend and resume behaviour</li></span>
            <span class="fragment"><li><code><a href="https://lewissbaker.github.io/2017/11/17/understanding-operator-co-await">await_ready</a></code>: is suspend required?</li></span>
            <span class="fragment"><li><code><a href="https://lewissbaker.github.io/2017/11/17/understanding-operator-co-await">await_suspend</a></code>: schedule resume</li></span>
            <span class="fragment"><li><code><a href="https://lewissbaker.github.io/2017/11/17/understanding-operator-co-await">await_resume</a></code>: <code>co_await</code> return result</li></span>
            <span class="fragment"><li>Can be the same as the <a href="https://lewissbaker.github.io/2017/11/17/understanding-operator-co-await">awaitable type</a></li></span>
          </ul>
          <aside class="notes">
          The await_ready method allows you to avoid the cost of suspending if you know that the operation is going to complete synchronously.
          <p>
          By contrast, the key purpose of the await_suspend method is to schedule the coroutine for resumption. In particular, once the await
          suspend method is called, the coroutine is suspended, so you are free to pass the coroutine handle to an executor so that the coroutine
          can be resumed later.
          <p>
          And then when the coroutine is resumed, the await_resume method is called to obtain the result of the operation and that is what is
          returned in the coroutine.
          </aside>
        </section>

        <section>
          <h2>Coroutine Return Type</h2>
          <ul>
            <span class="fragment"><li>Declares the promise type to the compiler</li></span>
            <span class="fragment"><ul><li>Using <code>coroutine_traits</code></li></ul></span>
            <span class="fragment"><li>E.g. '<code>task&ltT&gt</code>' or '<code>generator&ltT&gt</code>'</li></span>
            <span class="fragment"><li><a href="https://github.com/lewissbaker/cppcoro">CppCoro</a> defines several return types</li></span>
            <span class="fragment"><li>Referred to as a 'future' in some <a href="http://wg21.link/">WG21</a> papers</li></span>
            <span class="fragment"><li>Not to be confused with <code>std::future</code></li></span>
          </ul>
        </section>

        <section>
          <h2><a href="https://lewissbaker.github.io/2018/09/05/understanding-the-promise-type">Promise Type</a></h2>
          <ul>
            <span class="fragment"><li>Controls the coroutine's behaviour</li></span>
            <span class="fragment"><ul><li>... example coming up</li></ul></span>
            <span class="fragment"><li>Implements methods that are called at specific points during the execution of the coroutine</li></span>
            <span class="fragment"><li>Conveys coroutine result (or exception)</li></span>
            <span class="fragment"><li>Again - not to be confused with <code>std::promise</code></li></span>
          </ul>
        </section>

        <section>
          <h2><a href="https://lewissbaker.github.io/2018/09/05/understanding-the-promise-type">Customising Co_Await</a></h2>
          <ul>
            <span class="fragment"><li>The <code>await_transform</code> method:</li></span>
            <span class="fragment"><ul><li>Defined in the <code>promise_type</code></li></ul></span>
            <span class="fragment"><ul><li>Enables types that are not awaitable</li></ul></span>
            <span class="fragment"><ul><li>Disables <code>co_await</code> on certain types</li></ul></span>
            <span class="fragment"><ul><li>Modify the behaviour of awaitable values</li></ul></span>
            <span class="fragment"><li>Also possible to customise <code>co_yield</code></li></span>
            <span class="fragment"><li>See Lewis Baker's excellent <a href="https://lewissbaker.github.io/2018/09/05/understanding-the-promise-type">Blog Post</a> for details</li></span>
          </ul>
        </section>

        <section>
          <h2><a href="https://en.cppreference.com/w/cpp/coroutine/coroutine_handle">Coroutine Handles</a></h2>
          <ul>
            <span class="fragment"><li>Handle to a coroutine frame on the heap</li></span>
            <span class="fragment"><li>Means through which coroutines are resumed</li></span>
            <span class="fragment"><li>Also provide access to the promise type</li></span>
            <span class="fragment"><li>Non-owning - have to be destroyed explicitly</li></span>
            <span class="fragment"><ul><li>Often through RAII in the coroutine return type</li></ul></span>
          </ul>
          <aside class="notes">
            Bit like a C pointer
          </aside>
        </section>
      </section>

      <section>

        <section data-background-video="media/BWT_Intermission.mp4" data-background-video-loop=true>
          <h1>Coroutines Applied</h1>
        </section>

        <section>
          <h2>Observations</h2>
          <ul>
            <span class="fragment" style="color:yellow"><li>C++20 coroutines are powerful<span class="fragment" style="color:yellow"> ... but complex</span></li></span>
            <span class="fragment"><li>At the application level, how do we:</li></span>
            <ul>
              <span class="fragment"><li>Compare different forms of asynchrony</li></span>
              <span class="fragment"><li>Evaluate/benchmark performance</li></span>
              <span class="fragment"><li>Understand what's going on at the hardware level</li></span>
            </ul>
            <span class="fragment"><li>What is a practical methodology for doing this?</li></span>
          </ul>
          <aside class="notes">
          </aside>
        </section>

        <section>
          <h2><a href="https://www.boost.org/doc/libs/1_81_0/libs/beast/doc/html/index.html">Boost.Beast</a></h2>
          <ul>
            <span class="fragment"><li>HTTP and WebSocket built on <a href="https://www.boost.org/doc/libs/1_81_0/doc/html/boost_asio.html">Boost.Asio</a></li></span>
            <span class="fragment"><li>Excellent web server examples:</li></span>
            <ul>
              <span class="fragment"><li><a href="https://www.boost.org/doc/libs/1_81_0/libs/beast/example/http/server/async/http_server_async.cpp">Asynchronous</a> (callback based)</li></span>
              <span class="fragment"><li><a href="https://www.boost.org/doc/libs/1_81_0/libs/beast/example/http/server/coro/http_server_coro.cpp">Stackful coroutines</a> (<a href="">Boost.Coroutine</a>)</li></span>
              <span class="fragment"><li><a href="https://www.boost.org/doc/libs/1_81_0/libs/beast/example/http/server/coro/http_server_coro.cpp">C++20 coroutines</a> (awaitables)</li></span>
            </ul>
            <span class="fragment"><li>Recode for simplicity and test with <a href="https://httpd.apache.org/docs/2.4/programs/ab.html">Apache Bench</a></li></span>
          </ul>
          <aside class="notes">
            Yes. There's definitely still a use case for coroutine2. With c++20 coroutines, the only way to suspend a compound operation is if all parts are themselves coroutines. Specifically, if f calls a(), which calls b() which calls c() which calls d(), they must all be coroutine aware. They can't just "call" the next function, they must co_await it.

By contrast, with coroutine2 this isn't the case. a, b, c don't need to know that they're running in a coroutine at all. If d suspends by reading from a pull_type or writing to a push_type, the entire call sack suspends up to the nearest enclosing coroutine.

This has real advantages. For instance, by implementing an appropriate streambuf, I can use istream/ostream to lazily read/write anything. The higher level classes that implement operator<</operator>> are just regular code, as is the implementation of istream/osream. Yet when we need to fetch/flush more bytes the entire call stack can suspend.

On the other hand, if you don't need to suspend entire stacks of operations, or if all your code can be changed to be language coroutine aware, then the stackless coroutines of c++20 are a better tool than boost.coroutine2 was.

https://www.reddit.com/r/cpp/comments/10fkyru/are_boostcoroutine2_coroutines_still_relevant_now/
          </aside>
        </section>

        <section>
          <h2><a href="https://httpd.apache.org/docs/2.4/programs/ab.html">Apache Bench</a></h2>
          <ul>
            <span class="fragment"><li>'ab' is a tool for benchmarking HTTP servers</li></span>
            <span class="fragment"><li>Mature implementation with extensive set of options</li></span>
            <span class="fragment"><li>Number of concurrent requests is configurable</li></span>
            <span class="fragment" style="color:yellow"><li>Measures 'requests per second' that can be serviced</li></span>
          </ul>
          <aside class="notes">
          </aside>
        </section>

        <section>
          <h2><a href="">HTTP Server: Asynchronous</a></h2>
            <pre class="stretch"><code class="c++" style="width:105%" data-trim data-line-numbers="">
#include &ltboost/beast/core.hpp&gt
#include &ltboost/beast/http.hpp&gt
#include &ltboost/asio/strand.hpp&gt

#include &ltiostream&gt
#include &ltthread&gt
#include &ltformat&gt

namespace beast = boost::beast;
namespace http = beast::http;
namespace asio = boost::asio;
using tcp = boost::asio::ip::tcp;

void error(beast::error_code ec, char const* what)
{
  std::cerr &lt&lt std::format("Error: {} : {}\n", what, ec.message());
  return;
};

// Handles an HTTP server connection
class session : public std::enable_shared_from_this&ltsession&gt
{
  beast::tcp_stream stream_;
  beast::flat_buffer buffer_;
  http::request&lthttp::string_body&gt req_;

  public:
  // Take ownership of the stream
  session(
      tcp::socket&& socket)
    : stream_(std::move(socket))
  {
  }

  // Start the asynchronous operation
  void
    run()
    {
      asio::dispatch(stream_.get_executor(),
          beast::bind_front_handler(
            &session::do_read,
            shared_from_this()));
    }

  void
    do_read()
    {
      // Make the request empty before reading,
      // otherwise the operation behavior is undefined.
      req_ = {};

      // Set the timeout.
      stream_.expires_after(std::chrono::seconds(30));

      // Read a request
      http::async_read(stream_, buffer_, req_,
          beast::bind_front_handler(
            &session::on_read,
            shared_from_this()));
    }

  void
    on_read(
        beast::error_code ec,
        std::size_t bytes_transferred)
    {
      boost::ignore_unused(bytes_transferred);

      // This means they closed the connection
      if(ec == http::error::end_of_stream) {
        stream_.socket().shutdown(tcp::socket::shutdown_send, ec);
        return;
      }

      if(ec) return error(ec, "read");

      // Send the response
      auto handle_request = [this]() -&gt http::message_generator {
        http::response&lthttp::string_body&gt res{
          http::status::ok, req_.version()};
        res.set(http::field::server, "Boost.Beast");
        res.body() = "Hello ACCU 2023 from the Asynchronous Server!";
        res.prepare_payload();
        res.keep_alive(req_.keep_alive());
        return res;
      };

      beast::async_write(
          stream_,
          handle_request(),
          beast::bind_front_handler(
            &session::on_write, shared_from_this()));
    }

  void
    on_write(
        beast::error_code ec,
        std::size_t bytes_transferred)
    {
      boost::ignore_unused(bytes_transferred);

      if(ec) return error(ec, "write");

      stream_.socket().shutdown(tcp::socket::shutdown_send, ec);
      // Read another request
      do_read();
    }
};

// Accepts incoming connections and launches the sessions
class listener : public std::enable_shared_from_this&ltlistener&gt
{
  asio::io_context& ioc_;
  tcp::acceptor acceptor_;

  public:
  listener(
      asio::io_context& ioc,
      tcp::endpoint endpoint)
    : ioc_(ioc)
      , acceptor_(asio::make_strand(ioc))
  {
    beast::error_code ec;

    // Open the acceptor
    acceptor_.open(endpoint.protocol(), ec);
    if(ec) error(ec, "open");

    // Allow address reuse
    acceptor_.set_option(asio::socket_base::reuse_address(true), ec);
    if(ec) error(ec, "set_option");

    // Bind to the server address
    acceptor_.bind(endpoint, ec);
    if(ec) error(ec, "bind");

    // Start listening for connections
    acceptor_.listen(
        asio::socket_base::max_listen_connections, ec);
    if(ec) error(ec, "listen");
  }

  // Start accepting incoming connections
  void run()
  {
    do_accept();
  }

  private:
  void
    do_accept()
    {
      // The new connection gets its own strand
      acceptor_.async_accept(
          asio::make_strand(ioc_),
          beast::bind_front_handler(
            &listener::on_accept,
            shared_from_this()));
    }

  void
    on_accept(beast::error_code ec, tcp::socket socket)
    {
      if(ec) error(ec, "accept");

      // Create the session and run it
      std::make_shared&ltsession&gt(
          std::move(socket))-&gtrun();

      // Accept another connection
      do_accept();
    };
};

int main(int argc, char *argv[])
{
  if (argc != 4) {
    std::cerr &lt&lt std::format(
        "Usage: {} &ltip-address&gt &ltport&gt &ltthreads&gt\n"
        "E.g.: {} 0.0.0.0 8080 2\n",
        argv[0], argv[0]
        );
    return EXIT_FAILURE;
  }

  auto const address = asio::ip::make_address(argv[1]);
  auto const port = static_cast&ltunsigned short&gt(std::atoi(argv[2]));
  auto const num_threads = std::max&ltint&gt(1, std::atoi(argv[3]));

  asio::io_context ioc{num_threads};

  // Create and launch a listening port
  std::make_shared&ltlistener&gt(
    ioc, tcp::endpoint{address, port}
  )-&gtrun();

  // Run the IO service with the requested number of threads
  std::vector&ltstd::thread&gt v(num_threads-1);
  for (auto i = num_threads - 1; i; --i)
    v.emplace_back([&ioc]{ ioc.run(); });

  // Use the main thread as well
  ioc.run();

  return EXIT_SUCCESS;
}
            </code></pre>
          <aside class="notes">
          </aside>
        </section>

        <section data-menu-title="HTTP Server: Stackful">
          <h2><a href="">HTTP Server: Stackful Coroutines</a></h2>
            <pre class="stretch"><code class="c++" style="width:105%" data-trim data-line-numbers="">
#include &ltboost/beast/core.hpp&gt
#include &ltboost/beast/http.hpp&gt
#include &ltboost/beast/version.hpp&gt
#include &ltboost/asio/dispatch.hpp&gt
#include &ltboost/asio/strand.hpp&gt
#include &ltboost/asio/spawn.hpp&gt
#include &ltboost/config.hpp&gt

#include &ltiostream&gt
#include &ltmemory&gt
#include &ltthread&gt
#include &ltvector&gt
#include &ltformat&gt

namespace beast = boost::beast;
namespace http = beast::http;
namespace asio = boost::asio;
using tcp = boost::asio::ip::tcp;

// Report an error
void error(beast::error_code ec, char const* msg)
{
  std::cerr &lt&lt std::format("Error: {} - {}\n", msg, ec.message());
}

  void
do_session(
    beast::tcp_stream& stream,
    asio::yield_context yield)
{
  beast::flat_buffer buffer;
  beast::error_code ec;

  for(;;)
  {
    // Set a timeout (in case the client stops responding)
    stream.expires_after(std::chrono::seconds(30));

    // Read a request
    http::request&lthttp::string_body&gt req;
    http::async_read(stream, buffer, req, yield[ec]);

    if(ec == http::error::end_of_stream) break;

    if(ec) return error(ec, "read request");

    // Handle the request
    auto handle_request = [&req]() -&gt http::message_generator {
      http::response&lthttp::string_body&gt res{
        http::status::ok, req.version()
      };
      res.set(http::field::server, "Beast");
      res.body() = "Hello ACCU 2023 from the Stackful Coro Server!";
      res.prepare_payload();
      res.keep_alive(req.keep_alive());
      return res;
    };

    // Send the response
    beast::async_write(stream, handle_request(), yield[ec]);

    if(ec) return error(ec, "write response");

    // Determine if we should close the connection
    if(!req.keep_alive()) break;
  }

  // Close the connection
  stream.socket().shutdown(tcp::socket::shutdown_send, ec);
}

// Accepts incoming connections and launches the sessions
void do_listen(
    asio::io_context& ioc,
    tcp::endpoint endpoint,
    asio::yield_context yield)
{
  beast::error_code ec;

  // Open the acceptor
  tcp::acceptor acceptor(ioc);
  acceptor.open(endpoint.protocol(), ec);
  if(ec) return error(ec, "open");

  // Allow address reuse
  acceptor.set_option(asio::socket_base::reuse_address(true), ec);
  if(ec) return error(ec, "set_option");

  // Bind to the server address
  acceptor.bind(endpoint, ec);
  if(ec) return error(ec, "bind");

  // Start listening for connections
  acceptor.listen(asio::socket_base::max_listen_connections, ec);
  if(ec) return error(ec, "listen");

  for(;;)
  {
    tcp::socket socket(ioc);
    acceptor.async_accept(socket, yield[ec]);
    if(ec)
      error(ec, "accept");
    else
      boost::asio::spawn(
          acceptor.get_executor(),
          std::bind(
            do_session,
            beast::tcp_stream(std::move(socket)),
            std::placeholders::_1));
  }
}

int main(int argc, char *argv[])
{
  if (argc != 4) {
    std::cerr &lt&lt std::format(
        "Usage: {} &ltip-address&gt &ltport&gt &ltnum_threads&gt\n"
        "E.g.: {} 0.0.0.0 8080 2\n",
        argv[0], argv[0]
        );
    return EXIT_FAILURE;
  }

  auto const address = asio::ip::make_address(argv[1]);
  auto const port = static_cast&ltunsigned short&gt(std::atoi(argv[2]));
  auto const num_threads = std::max&ltint&gt(1, std::atoi(argv[3]));

  asio::io_context ioc{num_threads};

  // Spawn a stackful coroutine
  boost::asio::spawn(ioc,
      std::bind(
        &do_listen,
        std::ref(ioc),
        tcp::endpoint{address, port},
        std::placeholders::_1));

  // Run the IO service with the requested number of threads
  std::vector&ltstd::thread&gt v(num_threads-1);
  for (auto i = num_threads - 1; i; --i)
    v.emplace_back([&ioc]{ ioc.run(); });

  // Use the main thread as well
  ioc.run();

  return EXIT_SUCCESS;
}
            </code></pre>
          <aside class="notes">
          </aside>
        </section>

        <section data-menu-title="HTTP Server: Awaitables">
          <h2><a href="">HTTP Server: C++20 Coroutines</a></h2>
            <pre class="stretch"><code class="c++" style="width:105%" data-trim data-line-numbers="">
#include &ltboost/beast/core.hpp&gt
#include &ltboost/beast/http.hpp&gt
#include &ltboost/asio/awaitable.hpp&gt
#include &ltboost/asio/co_spawn.hpp&gt
#include &ltboost/asio/use_awaitable.hpp&gt

#include &ltiostream&gt
#include &ltthread&gt
#include &ltvector&gt
#include &ltformat&gt

namespace beast = boost::beast;
namespace http = beast::http;
namespace asio = boost::asio;
using tcp = boost::asio::ip::tcp;

using tcp_stream = typename beast::tcp_stream::rebind_executor&lt
  asio::use_awaitable_t&lt&gt::
    executor_with_default&ltasio::any_io_executor&gt&gt::other;

// Handles an HTTP server connection
asio::awaitable&ltvoid&gt do_session(tcp_stream stream)
{
  beast::error_code ec;

  // This buffer is required to persist across reads
  beast::flat_buffer buffer;

  for(;;) {
    try
    {
      // Set the timeout.
      stream.expires_after(std::chrono::seconds(30));

      // Read a request
      http::request&lthttp::string_body&gt req;
      co_await http::async_read(stream, buffer, req);

      // Handle the request
      auto handle_request = [&req]() -&gt http::message_generator {
        http::response&lthttp::string_body&gt res{
          http::status::ok,
            req.version()
        };
        res.set(http::field::server, "Beast");
        res.body() = "Hello ACCU 2023 from the Awaitable Server!";
        res.prepare_payload();
        res.keep_alive(req.keep_alive());
        return res;
      };

      // Send response
      co_await beast::async_write(
        stream, handle_request(), asio::use_awaitable
      );

      // Determine if we should close the connection
      if(!req.keep_alive()) break;
    }
    catch (boost::system::system_error & se)
    {
      if (se.code() != http::error::end_of_stream)
        throw;
    }
  }

  // Send a TCP shutdown
  stream.socket().shutdown(tcp::socket::shutdown_send, ec);
}

// Accepts incoming connections and launches the sessions
asio::awaitable&ltvoid&gt do_listen(tcp::endpoint endpoint)
{
  // Open the acceptor
  auto acceptor = asio::use_awaitable.as_default_on(
    tcp::acceptor(co_await asio::this_coro::executor)
  );
  acceptor.open(endpoint.protocol());

  // Allow address reuse
  acceptor.set_option(asio::socket_base::reuse_address(true));

  // Bind to the server address
  acceptor.bind(endpoint);

  // Start listening for connections
  acceptor.listen(asio::socket_base::max_listen_connections);

  for(;;)
    boost::asio::co_spawn(
      acceptor.get_executor(),
      do_session(tcp_stream(co_await acceptor.async_accept())),
      [](std::exception_ptr e)
      {
        try
        {
          if (e) std::rethrow_exception(e);
        }
        catch (std::exception &e) {
          std::cerr &lt&lt "Error in session: " &lt&lt e.what() &lt&lt "\n";
        }
      }
    );
}

int main(int argc, char* argv[])
{
  // Check command line arguments.
  if (argc != 4) {
    std::cerr &lt&lt std::format(
      "Usage: {} &ltip-address&gt &ltport&gt &ltthreads&gt\n"
      "E.g.: {} 0.0.0.0 8080 1\n",
      argv[0], argv[0]
    );
    return EXIT_FAILURE;
  }

  auto const address = asio::ip::make_address(argv[1]);
  auto const port = static_cast&ltunsigned short&gt(std::atoi(argv[2]));
  auto const num_threads = std::max&ltint&gt(1, std::atoi(argv[3]));

  // The io_context is required for all I/O
  asio::io_context ioc{num_threads};

  // Spawn a listening port
  boost::asio::co_spawn(ioc,
    do_listen(tcp::endpoint{address, port}),
    [](std::exception_ptr e)
    {
      try
      {
        if (e) std::rethrow_exception(e);
      }
      catch(std::exception & e)
      {
        std::cerr &lt&lt "Error in acceptor: " &lt&lt e.what() &lt&lt "\n";
      }
    }
  );

  // Run the I/O service on the requested number of threads
  std::vector&ltstd::thread&gt v(num_threads-1);
  for (auto i = num_threads - 1; i; --i)
    v.emplace_back([&ioc]{ ioc.run(); });

  // Use the main thread as well
  ioc.run();

  return EXIT_SUCCESS;
}
            </code></pre>
          <aside class="notes">
          </aside>
        </section>

        <section data-menu-title="Web Server Example Video"
                 data-state="hideControls",
                 data-background-video="media/beast-example-terminal-capture-1080.mp4"
                 id="video">
        </section>

        <section data-menu-title="Performance: x86-64">
          <h3>Web Server Performance Comparison: x86-64</h3>
          <canvas data-chart="bar">
          <!--
          {
            "data" : {
              "labels" : ["1", "10", "100", "250", "500", "1000"],
              "datasets" : [
              {
                "label": "Asynchronous",
                "data": [2867.19, 9407.40, 10577.73, 10558.98, 6870.57, 6904.21]
              }, {
                "label": "Boost.Coroutine",
                "data": [3154.04, 10670.68, 11149.29, 6893.41, 6700.10, 6921.70]
              }, {
                "label": "C++20 Coroutines",
                "data": [4054.45, 9228.29, 9942.40, 11647.31, 12484.03, 11732.35]
              }]
            },
            "options" : {
              "legend":
              {
                "labels": {"boxWidth":10}
              },
              "scales":
              {
                "yAxes": [
                {
                  "ticks": {"beginAtZero":true},
                  "scaleLabel": {"display": true, "labelString": "Requests Per Second"}
                }],
                "xAxes": [
                {
                  "scaleLabel": {"display": true, "labelString": "Number of Simultaneous Connections (100000 requests)"}
                }]
              }
            }
          }
          -->
          </canvas>
        </section>

        <section data-menu-title="Time Per Request: x86-64">
          <h3>Time Per Request (ms): x86-64</h3>
          <canvas data-chart="bar">
          <!--
          {
            "data" : {
              "labels" : ["1", "10", "100", "250", "500", "1000"],
              "datasets" : [
              {
                "label": "Asynchronous",
                "data": [0.349, 0.106, 0.095, 0.095, 0.146, 0.114]
              }, {
                "label": "Boost.Coroutine",
                "data": [0.317, 0.094, 0.090, 0.145, 0.149, 0.280]
              }, {
                "label": "C++20 Coroutines",
                "data": [0.247, 0.108, 0.101, 0.086, 0.112, 0.147]
              }]
            },
            "options" : {
              "legend":
              {
                "labels": {"boxWidth":10}
              },
              "scales":
              {
                "yAxes": [
                {
                  "ticks": {"beginAtZero":true},
                  "scaleLabel": {"display": true, "labelString": "Mean Time Per Request (ms)"}
                }],
                "xAxes": [
                {
                  "scaleLabel": {"display": true, "labelString": "Number of Simultaneous Connections (100000 requests)"}
                }]
              }
            }
          }
          -->
          </canvas>
        </section>
      </section>

      <section>

        <section data-background-video="media/BWT_Intermission.mp4" data-background-video-loop=true>
          <h1>Conclusions</h1>
        </section>

        <section>
          <h2>Debugging Tips</h2>
          <ul>
            <span class="fragment"><li>Design concurrency before implementing</li></span>
            <ul>
              <span class="fragment"><li>Eliminate bugs by design e.g. race conditions</li></span>
            </ul>

            <span class="fragment"><li>Be careful with object lifetimes</li></span>
            <ul>
              <span class="fragment"><li>Common idiom: RAII class that inherits from <span style="color:yellow">std::enable_shared_from_this</span></li></span>
              <span class="fragment"><li>Check for resource exhaustion e.g. <span style="color:yellow">lsof -p <pid></span></li></span>
            </ul>
          <aside class="notes">
          One common idiom is to managing object lifetime is to have the I/O object be managed by a single class that inherits from enable_shared_from_this. When a class inherits from enable_shared_from_this, it provides a shared_from_this() member function that returns a valid shared_ptr instance managing this. A copy of the shared_ptr is passed to completion handlers, such as a capture-list in lambdas or passed as the instance handle to bind(), causing the lifetime of the I/O object to be extended to at least as long as the handler. See the Boost.Asio asynchronous TCP daytime server tutorial for an example using this approach.
          </aside>
        </section>

        <section>
          <h2>C++23 Stacktrace</h2>
            <ul>
              <span class="fragment"><li>C++23 <a href="https://en.cppreference.com/w/cpp/header/stacktrace">stacktrace</a> can be very helpful:</li></span>
              <ul>
                <span class="fragment"><li>Good support in gcc 12.2</li></span>
                <span class="fragment"><li>Configure with: <span style="color:yellow">--enable-libstdcxx-backtrace=yes</span></li></span>
                <span class="fragment"><li>Compile with: <span style="color:yellow">-std=c++23 -lstdc++_libbacktrace</span></li></span>
              </ul>
            </ul>
          <aside class="notes">
          </aside>
        </section>

        <section>
          <h2>C++23/26 Coroutine Update</h2>
            <ul>
              <span class="fragment"><li><a href="http://wg21.link/p2502">P2502</a>: standardised generator <code>std::generator</code></li></span>
              <span class="fragment"><ul><li>Models <code>std::ranges::input_range</code></li></ul></span>
              <span class="fragment"><ul><li>Approved for C++23 (June 2022)</li></ul></span>
              <span class="fragment"><ul><li>Not yet implemented in standard libraries</li></ul></span>
              <span class="fragment"><ul><li>Reference implementation: <a href="https://godbolt.org/z/5hcaPcfvP">godbolt.org</a></li></ul></span>

              <span class="fragment"><li><a href="http://wg21.link/p2300">P2300R6</a>: <code>std::execution</code></li></span>
              <span class="fragment"><ul><li>Standardised asynchronous execution</li></ul></span>
              <span class="fragment"><ul><li>... on generic execution contexts</li></ul></span>
              <span class="fragment"><ul><li>Targeting C++26 (see also: <a href="https://github.com/facebookexperimental/libunifex">libunifex</a>)</li></ul></span>
            </ul>
            <aside class="notes">
The coroutine language feature mitigates these shortcomings somewhat with the HALO optimization Halo: coroutine Heap Allocation eLision Optimization: the joint response, which leverages existing compiler optimizations such as allocation elision and devirtualization to inline the coroutine, completely eliminating the runtime overhead. However, HALO requires a sophisticated compiler, and a fair number of stars need to align for the optimization to kick in. In our experience, more often than not in real-world code today’s compilers are not able to inline the coroutine, resulting in allocations and indirections in the generated code.

In a suite of generic async algorithms that are expected to be callable from hot code paths, the extra allocations and indirections are a deal-breaker. It is for these reasons that we consider coroutines a poor choice for a basis of all standard async.
            </aside>
        </section>

        <section>
          <h2>Conclusion</h2>
            <ul>
              <span class="fragment"><li>Fibers provide a light-weight alternative to threading</li></span>
              <span class="fragment"><ul><li>Combines concurrency with parallelism</li></ul></span>
              <span class="fragment"><li>Coroutines allow asynchronous code to be written</li></span>
              <span class="fragment"><ul><li>With the readability of synchronous code</li></ul></span>
              <span class="fragment"><li>Using coroutines in user-code:</li></span>
              <span class="fragment"><ul><li><a href="https://www.boost.org/doc/libs/1_81_0/doc/html/boost_asio.html">Boost.Asio</a> and <a href="https://www.boost.org/doc/libs/1_81_0/libs/beast/doc/html/index.html">Boost.Beast</a> are great for this</li></ul></span>
              <span class="fragment"><ul><li>Persevere with <a href="#/key-references">key references</a></li></ul></span>
            </ul>
        </section>

        <section>
          <h2>Questions?</h2>
          <p><p>
          <a href="http://www.james-pascoe.com">http://www.james-pascoe.com</a><br>
          <a href="mailto:james@james-pascoe.com">james@james-pascoe.com</a><p>

          <a href="http://jamespascoe.github.io/accu2023">http://jamespascoe.github.io/accu2023</a><br>
          <a href="https://github.com/jamespascoe/accu2023-example-code.git"><font size="6">https://github.com/jamespascoe/accu2023-example-code.git</font></a>
          <p>
          <font style="color:yellow">ACCU Bristol and Bath Meetup Coordinator</font>
        </section>

      </section>

      </div>
    </div>

    <script src="dist/reveal.js"></script>
    <script src="plugin/notes/notes.js"></script>
    <script src="plugin/markdown/markdown.js"></script>
    <script src="plugin/highlight/highlight.js"></script>
    <script src="plugin/menu/menu.js"></script>
    <script src="plugin/chart/Chart.min.js"></script>
    <script src="plugin/chart/plugin.js"></script>
    <script>
      // More info about initialization & config:
      // - https://revealjs.com/initialization/
      // - https://revealjs.com/config/
      Reveal.initialize({
        hash: true,
        controls: true,
        totalTime: 5400,
        hideInactiveCursor: true,
        hideCursorTime: 2000,
        hideAddressBar: true,
        preloadIframes: true,
        progress: false,
        touch: true,
        keyboard: true,
        keyboard: {
          67: () => { /* Keycode for the letter 'c' i.e. 'controls' */
            var currentSlide = Reveal.getCurrentSlide();
            var currentVideo = currentSlide.slideBackgroundContentElement.getElementsByTagName("video")[0];
            if (currentVideo) {
              /* Toggle video controls on/off */
              currentVideo.controls = !currentVideo.controls
            }
          },
          32: () => { /* Keycode for spacebar */
            var currentSlide = Reveal.getCurrentSlide();
            var currentVideo = currentSlide.slideBackgroundContentElement.getElementsByTagName("video")[0];
            if (currentVideo) {
              /* Pause/resume video when the spacebar is pressed */
              if (currentVideo.paused == true) currentVideo.play();
              else currentVideo.pause();
            }
            else {
              /* Advance to next slide if no video (default Reveal behaviour) */
              Reveal.next();
            }
          }
        },
        chart: {
          defaults: {
            global: {
              title: { fontColor: "#FFF" },
              legend: {
                position: "bottom",
                labels: { fontColor: "#FFF" },
              },
              tooltips: {
                labels: { fontColor: "#FFF" },
              },
            },
            scale: {
              scaleLabel: { fontColor: "#FFF" },
              gridLines: { color: "#FFF", zeroLineColor: "#FFF" },
              ticks: { fontColor: "#FFF" },
            }
          },
          bar: { backgroundColor: [ "rgba(20,220,220,.8)" , "rgba(220,120,120,.8)", "rgba(20,120,220,.8)", "rgba(255, 159, 64, .8)","rgba(255, 205, 86, .8)", "rgba(153, 102, 255, .8)" ]},
        },
        menu: {
          themes: true,
          delayInit: true
        },
        pdfSeparateFragments: false,
        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMenu, RevealChart ]
      });

      Reveal.addEventListener('hideControls', function() {
        Reveal.configure({controls: false});
        menu_button = document.getElementsByClassName("slide-menu-button")[0];
        if (menu_button) {
          menu_button.style.display = 'none';
        }
      }, false );

      Reveal.addEventListener('slidechanged', function() {
        /* Ensure that the Reveal controls and Menu are available on
         * all slides other than the 'Title-Slide'.
         */
        slide_id = Reveal.getCurrentSlide().getAttribute("id");

        if (slide_id !== "Title-Slide" && slide_id !== "video") {
          config = Reveal.getConfig();
          if (config["controls"] !== true) {
            Reveal.configure({controls: true});
          }

          menu = Reveal.getPlugin("menu");
          if (!menu.isMenuInitialised()) {
            menu.initialiseMenu();
          }
          menu_button = document.getElementsByClassName("slide-menu-button")[0];
          if (menu_button) {
            menu_button.style.display = '';
          }
        }
      }, false );

      Reveal.addEventListener('increasePlaybackSpeed', function() {
        var currentSlide = Reveal.getCurrentSlide();
        var currentVideo = currentSlide.slideBackgroundContentElement.getElementsByTagName("video")[0];
        if (currentVideo) {
          currentVideo.playbackRate = 2.0;
        }
      }, false );
   </script>
  </body>
</html>
